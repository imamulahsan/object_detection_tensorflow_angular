# Live Website
https://simpledetectors.netlify.app/

# Object Detection, Image Classification and Hand Gesture Detection
Key Features:
Object Detection – Identifies objects in real-time using TensorFlow's COCO-SSD model.
Image Classification – Quickly classifies images with high accuracy.
Hand Gesture Recognition – Using MediaPipe and TensorFlow.js to detect and respond to hand gestures in real-time.
This project leverages TensorFlow.js for real-time machine learning directly in the browser, making the application highly interactive and responsive. With Angular as the front-end framework, the UI/UX is smooth and intuitive.
It feels great to be back into machine learning after a long break, and I’m thrilled to see these applications in action


# Technologies Used
- Angular 17
- TensorflowJS
- HTML5
- CSS3
- Typescript


# ObjectDetectionAngularTensorflow

This project was generated with [Angular CLI](https://github.com/angular/angular-cli) version 17.3.7.

## Development server

Run `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The application will automatically reload if you change any of the source files.

## Code scaffolding

Run `ng generate component component-name` to generate a new component. You can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`.

## Build

Run `ng build` to build the project. The build artifacts will be stored in the `dist/` directory.

## Running unit tests

Run `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).

## Running end-to-end tests

Run `ng e2e` to execute the end-to-end tests via a platform of your choice. To use this command, you need to first add a package that implements end-to-end testing capabilities.

## Further help

To get more help on the Angular CLI use `ng help` or go check out the [Angular CLI Overview and Command Reference](https://angular.io/cli) page.
